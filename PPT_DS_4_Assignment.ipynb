{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMd08HtFvhBMmlqborW/awH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kajal1301/Pwskills/blob/main/PPT_DS_4_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Linear Model:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8wLi8BsR7uEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. What is the purpose of the General Linear Model (GLM)?\n"
      ],
      "metadata": {
        "id": "YZV9ddpw7zIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* General linear model (GLM) is used to analyse and understand the relationship\n",
        "between a dependent variable (output feature) and one or more independent variables.\n",
        "* It is widely used in various felids such as regression analysis analysis of variance (ANOVA) and analysis of covariance (ANCOVA).\n",
        "* GLM assumes that dependent variable follows a normal distribution and the relationship between dependend and independent variable is linear.\n",
        "* GLM provides a framework for hypothesis testing, model comparison and estimation of parameters.\n",
        "\n"
      ],
      "metadata": {
        "id": "kYSb6vrgP3M3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. What are the key assumptions of the General Linear Model?\n"
      ],
      "metadata": {
        "id": "89q0qy4c7zF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key assumptions of General Linear Model are:-\n",
        "1.\tLinearity : GLM assumes that the relationship between dependent variable and independent variables is linear.\n",
        "2.\tIndependence: This states that there should be no systematic relationship or dependency between the independent variables. If this condition violates, it can lead to biased and inefficient estimates.\n",
        "3.\tHomoscedasticity: Homoscedasticity assumes that variance of errors is constant across all independent variables.\n",
        "4.\tNormality: GLM assures that the errors or residuals follow normal distribution. This is necessary for hypothesis testing, confidence interval and model inderence.\n",
        "5.\tNo Multicollinearity: It refers to degree of correlation between independent variables. GLM assumes that independent variables are not correlated with each other.\n",
        "6.\tNo Endogeneity: GLM assumes that there is no correlation between the error term and one or more independent variables. Which if happens can lead to biased and inconsistent estimates.\n",
        "7.\tCorrect Specification: GLM assumes that model is correctly specified. Means the functional form of relationship between the variables is accurately represented in the model\n"
      ],
      "metadata": {
        "id": "pe8ROCv3QEbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. How do you interpret the coefficients in a GLM?\n"
      ],
      "metadata": {
        "id": "Fmwm8dVj7zDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cofficients in GLM depends on the specific model and variables used. In general coefficients provide information about the magnitude and direction of the effect that each independent variable has on the dependent variable, assuming all other variables in the model are held constant.\n",
        "1.\tcoefficient sign:  (+ or - ) sign indicates the direction of the relationship between the independent and dependent variable.\n",
        "2.\tMagnitude: magnitude reflects the size of effect that the independent variable has on the dependent variable, all else being equal.\n",
        "3.\tStatistical Significance: the statistical significance of a coefficient is determined by its p-value.\n",
        "4.\tAdjusted vs Unadjusted Coefficients: Model with independent variable might have adjusted coefficients sometimes. Adjusted coefficients provide a more accurate estimate of the relationship between a specific independent variable and dependent variable.\n"
      ],
      "metadata": {
        "id": "t0BhO8JfQK4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. What is the difference between a univariate and multivariate GLM?\n",
        "\n"
      ],
      "metadata": {
        "id": "Gaa5a3pO7zA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In **univariate GLM**, a single dependent variable is present having more than 1 independent variables. The goal of this model is to explain the variation of the sinhle dependent varuable with other independent variables.\n",
        "Example: linear regression, logistic regression\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In **Multivariate GLM**, there are multiple dependent variables analyzed simultaneously by taking their relationships into account with their predictor variables.\n",
        "Example: multivariate regression, multivariate analysis of variance (MANOVA)\n"
      ],
      "metadata": {
        "id": "zVgocvawQPR3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Explain the concept of interaction effects in a GLM.\n"
      ],
      "metadata": {
        "id": "4xdl-Rd57y9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In GLM, Interaction effects refer to the combined effect of two or more independent variables on the dependent variable that is greater (or lesser) than the sum of their individual effects. There are two kinds of interaction effects:\n",
        "1. Simple Interaction: A simple interaction occurs when one independent variable on the another independent variable.\n",
        "2. Complex Interaction: It occues whenone independent variable is dependent on two or more dependent variables."
      ],
      "metadata": {
        "id": "SloleOq2RjoB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. How do you handle categorical predictors in a GLM?\n"
      ],
      "metadata": {
        "id": "aoAwxmSM7y7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In GLM categorical variables are handled via data encoding. Some of the data encoding techniques are:\n",
        "1.\t**One hot encoding**: In One Hot Encoding, each category is represented as a binary vector, where each bit corresponds to a unique category.\n",
        "Disadvantage of this type of encoding is that if we are having 100 categorical features, this will create 100 features which will increase dimensionality of data.\n",
        "Also it will create a sparse matrix.\n",
        "\n",
        "2. **Label Encoding**: It assigns a unique numerical label to each category in the variable.\n",
        "\tDisadvantage: it randomly assigns number as per alphabetical order and thus it might decrease the importance of a categorical variable.\n",
        "3. **Ordinal Encoding**: It helps assign ranks to the labels/ categorical data. In this technique each category is assigned a neumerical value based on its position in the order.\n",
        "4. **Target guided Ordinal Encoding**: this technique is used to encode each categorical variable based on their relationship with the target variable. This encoding is useful when we have a categorical variable with large number of unique categories. Here, we replace categorical variable with a numerical value based on the mean and median of the target variable for that category.\n",
        "\n"
      ],
      "metadata": {
        "id": "C5VFXwP0QzJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. What is the purpose of the design matrix in a GLM?\n"
      ],
      "metadata": {
        "id": "V4ACURnV7y4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Design matrix is a crucial component of GLM. It is a structured representation of independent variables in GLM organised in matrix format.\n",
        "The purpose of design matrix in GLM are:\n",
        "1. Encoding Independent Variables : The design matrix represents independent variables in a structured manner where each matrix corresponds to a specific independent variable, and each row corresponds to an observation or data point. It encodes the values of the independent variables for each observation, allowing GLM to incorporate them into the model.\n",
        "2. Incorporating Nonlinear Relationships:\n",
        "The design matrix can include  interactions of the original independent variables to analyse nonlinear relationships between the predictors and the dependent variable.\n",
        "\n",
        "3. Handling Categorical Variables:\n",
        "It is important to handle categorical variables in GLM as model only understands numerical value. This is done by data encoding.\n",
        "4. Estimating Coefficients:\n",
        "The design matrix allows the GLM to estimate the coefficients for each independent variable. By incorporating the design matrix into the GLM's estimation procedure, the model determines the relationship between the independent variables and the dependent variable, estimating the magnitude and significance of the effects of each predictor.\n",
        "\n",
        "5. Making Predictions:\n",
        "Once the GLM estimates the coefficients, the design matrix is used to make predictions for new, unseen data points. By multiplying the design matrix of the new data with the estimated coefficients, the GLM can generate predictions for the dependent variable based on the values of the independent variables.\n",
        "\n"
      ],
      "metadata": {
        "id": "VqIfpi-jTkbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. How do you test the significance of predictors in a GLM?\n"
      ],
      "metadata": {
        "id": "GK78dUXe7y1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can test significance of predictors in GLM by following ways:\n",
        "1. Hypothesis testing\n",
        "2. Chi square test\n",
        "3. ANOVA test\n",
        "4. By estimating coefficients\n"
      ],
      "metadata": {
        "id": "rGEUFD-8UxEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. What is the difference between Type I, Type II, and Type III sums of squares in a GLM?\n"
      ],
      "metadata": {
        "id": "a2TqqsxS7yyq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **TYPE I sums of squares**:Type I Sums of Squares, or also called Sequential Sums of Squares, assign variation to the different variables in a sequential order.It calculates the reduction in the error sum of squares by adding each predictor variable sequentially in the order specified.\n",
        "\n",
        "* TYPE II Sums of square: Type II sums of squares assess the significance of each predictor variable in the model while adjusting for the effects of other variables already in the model. It calculates the reduction in the error sum of squares by adding each predictor variable, ignoring the order of variable entry.\n",
        "* **TYPE III Sums of square:** Type III sums of squares assess the significance of each predictor variable in the model, taking into account the effects of all other variables in the model. It calculates the reduction in the error sum of squares by adding each predictor variable, adjusting for the effects of all other variables."
      ],
      "metadata": {
        "id": "stEw-dcwVowJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Explain the concept of deviance in a GLM."
      ],
      "metadata": {
        "id": "M9R-hDwF7yv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a GLM, deviance is a measure of goodness of fit of the model. It quantifies the discrepency between the observed data and the predictions made by the model.\n",
        "The deviance is calculated as follows:\n",
        "\n",
        "Deviance = -2 * (log-likelihood of fitted model - log-likelihood of saturated model)"
      ],
      "metadata": {
        "id": "-kux5bD07ytX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vi4iVS0y7yqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What is regression analysis and what is its purpose?\n"
      ],
      "metadata": {
        "id": "XEqhiYrI7ynL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression is a kind of Supervised Machine Learning which is used when the dependent feature is having continuous value.\n",
        "\n",
        "For example : heights of students in the class.\n",
        "The purpose of regression analysis is to find the relationship between independent and dependent features where the dependent (output) variable is having continuous values."
      ],
      "metadata": {
        "id": "GmGAhZ3PX05g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is the difference between simple linear regression and multiple linear regression?\n"
      ],
      "metadata": {
        "id": "S4OJmI2pYUKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In **simple linear Regression**, there is only 1 independent variable which is used to estimate or predict the dependent variable. Here we can assume that the dependent variable is having a linear relationship witht he independent variable. The goal here is to find the best fit line that minimizes the difference between the observed values and predicted values based on linear relationship.\n",
        "\n",
        "In Multiple Linear Regression, There are two or more than 3 independent variables that are used to estimate or predict the dependent variable. The goal here is to find the best fit line or hyperplane that minimizes the relationship between multiple independent variables and the dependent variable."
      ],
      "metadata": {
        "id": "1IoZ0RH1YUHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13. How do you interpret the R-squared value in regression?"
      ],
      "metadata": {
        "id": "pkQXBoltYUFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "R-squared is also known as coefficient of determination. It is a statistical measure that represents the proportion of variance in the dependent variable that is explained by the independent variables in a regression model.\n",
        " * R-squared= 1 - SS_res/SS_total\n",
        "* where SS_res= sum of squares of residuals\n",
        "* SS_total= sum of squares of total\n",
        " * It ranges between 0 and 1.\n",
        " * If R-square value reaches towards 1, then this is the case of overfitting.\n",
        ""
      ],
      "metadata": {
        "id": "i1AxfgtpZeRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 14. What is the difference between correlation and regression?\n"
      ],
      "metadata": {
        "id": "j78kSlZFZeNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Correlation** is a satistical measure that establishes the relationships between two variables.\n",
        "It quantifies how closely the values of two variables are related to each other. Correlation coefficients range from -1 to +1, where -1 indicates a perfect negative correlation, +1 indicates a perfect positive correlation, and 0 indicates no correlation.\n",
        "* **Regression**, on the other hand, is a statistical technique used to model the relationship between a dependent variable and one or more independent variables.\n",
        "Regression analysis can be used to understand the impact of specific variables on the outcome and make predictions or infer causal relationships."
      ],
      "metadata": {
        "id": "Pn2artNzZeKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 15. What is the difference between the coefficients and the intercept in regression?"
      ],
      "metadata": {
        "id": "W79MsJ0oZeFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Intercept:**\n",
        "The intercept, often denoted as \"b₀\" or \"β₀,\" is the value of the dependent variable when all independent variables in the model are set to zero. It represents the baseline or starting point of the regression line or surface.\n",
        "* Coefficients:\n",
        "The coefficients, also known as regression coefficients, they capture the relationship between the dependent variable and each independent variable. They indicate the direction (positive or negative) and magnitude of the effect that each independent variable has on the dependent variable.\n"
      ],
      "metadata": {
        "id": "CxiQaKj9ZeCl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 16. How do you handle outliers in regression analysis?"
      ],
      "metadata": {
        "id": "6VSFt0ECZd_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In regression, if there are outliers then it squared error will become too high, thus effecting the performance of the model.\n",
        "Thus outliers can be handled using multiple ways:-\n",
        "1. If the points are too far, then they can be reduced.\n",
        "2. Variables can be transformed /standardized/ Normalized to reduce the outliers.\n",
        "3. In case of polynomial regression, we can take small clusters of data points to check the behaviour of outliers.\n",
        "\n"
      ],
      "metadata": {
        "id": "rJRBj1TfYUCx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 17. What is the difference between ridge regression and ordinary least squares regression?"
      ],
      "metadata": {
        "id": "vQGZF3HgwdIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* One of the disadvantages of using Linear regression (Ordinary least squares) is overfitting.\n",
        "*  So it is essential to find solutions that help provide more regularization. One of the solutions is Ridge Regression.\n",
        "* Ridge regression is a linear model for regression like Linear regression (Ordinary least squares).\n",
        "*  But there is a difference that helps make the Ridge regression more regularized and thus avoid the problem of overfitting.\n",
        "* The ordinary least squares model seeks to find the coefficients that minimize the mean squared error.\n",
        "* On the other hand, Ridge Regression tries to find the coefficients that minimize the mean squared error and wants the magnitude of coefficients to be as small as possible. That means each feature should have a little effect on the outcome.\n",
        "* Therefore, Ridge Regression will perform worse than the ordinary least squares model on the training set. But it will give us better regularization and performance on the test set.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BBUG0luzv1AO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 18. What is heteroscedasticity in regression and how does it affect the model?"
      ],
      "metadata": {
        "id": "_3ncjJxwv08_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heteroscedasticity in regression refers to a situation where the variability of the errors (residuals) in a regression model is not constant across different values of dependent variable. In other words, the spread of the residuals varies as the values of the independent variables change. This violates one of the assumptions of classical linear regression, known as homoscedasticity or constant variance of errors.\n",
        "It affects the model by:\n",
        "1. Giving Inaccurate Predictions,\n",
        "2. Inefficient standard errors\n",
        "3. Estimating Biased Coefficients"
      ],
      "metadata": {
        "id": "7CIg12_nv05e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 19.How do you handle multicollinearity in regression analysis?"
      ],
      "metadata": {
        "id": "vk8jAuVHxL2R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Muticollinearty in regression can be handled by:-\n",
        "1. Identifying the collinearity of features.\n",
        "2. Removing one of the correlated features.\n",
        "3. Feature Selection\n",
        "4. Reducing Dimensions of the data with the help of dimensionality reduction techniques such as PCA, Tsne etc.\n",
        "5. Feature Standardization and Feature Normalization"
      ],
      "metadata": {
        "id": "NRJ3GONRxLww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 20. What is polynomial regression and when is it used?"
      ],
      "metadata": {
        "id": "03C-0dRDYT_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Polynomial Regression is an extension of linear Regression that models the relationship between the independent variables and the dependent variable as a higher degree polynomial function.\n",
        "* It allows capturing non- linear relationship between the variables.\n",
        "* Polynomial regression is used in situations where the relationship between the variables is not linear and cannot be adequately represented by a straight line.\n",
        "* It is particularly useful when there is prior knowledge or a theoretical basis to believe that the relationship between the variables should be nonlinear, or when examining data patterns suggests a curvilinear relationship.\n"
      ],
      "metadata": {
        "id": "hfSDPom1YT9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function:"
      ],
      "metadata": {
        "id": "hvz82lS5y_XP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 21. What is a loss function and what is its purpose in machine learning?"
      ],
      "metadata": {
        "id": "nu2uq5jgy_Sf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Loss function, in machine learning is also known as error function or cost function.\n",
        "* It is a mathematical measure that quantifies the discrepency between the predicted and observed values of dependent variable.\n",
        "*  The purpose of loss function is to provide a measure of how well the model is performiing to help the learning process to minimize the error between observed values and actual values.\n"
      ],
      "metadata": {
        "id": "Bgksvl5d0tn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 22. What is the difference between a convex and non-convex loss function?"
      ],
      "metadata": {
        "id": "RMe0Rwi3y_Pn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Convex Loss Function:**\n",
        "A convex loss function is one in which the combination of any two points on the loss function curve lies above or on the curve itself.\n",
        "\n",
        " Mathematically, a function f(x) is convex if, for any two points x₁ and x₂ in its domain and any value λ between 0 and 1, the following condition holds:\n",
        "\n",
        "f(λx₁ + (1 - λ)x₂) ≤ λf(x₁) + (1 - λ)f(x₂)\n",
        "\n",
        "In simpler terms, if you draw a straight line connecting any two points on the curve, the line will always lie above the curve.\n",
        "* **Non-Convex Loss Function:**\n",
        "A non-convex loss function does not satisfy the convexity property. In other words, there exist points on the loss function curve for which the line connecting two of those points dips below the curve.\n",
        "\n",
        "Non-convex loss functions often have multiple local minima, making it more challenging to find the optimal solution. Optimization algorithms may converge to a local minimum instead of the global minimum, resulting in a suboptimal solution."
      ],
      "metadata": {
        "id": "TeSrLOuo1Pm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 23. What is mean squared error (MSE) and how is it calculated?"
      ],
      "metadata": {
        "id": "N2DxbPUFzzKk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Squared Error is a loss function used in regression problems to measure the average squared difference between the predicted values and the true values of the target variable. It quantifies the overall goodness of fit of the regression model.\n",
        "* Its advantages are:-\n",
        "It is differentiable and also has only 1 local and 1 global minima.\n",
        "* Its disadvantage is that MSE is not Robust to outliers. Also squaring the loss will square the unit of the variable as well.\n",
        "\n",
        "Mathematically, the MSE can be represented as:\n",
        "\n",
        "MSE = SSE / n\n",
        "\n",
        "where SSE is the sum of squared errors and n is the number of data points."
      ],
      "metadata": {
        "id": "UYntF8XV1lMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 24. What is mean absolute error (MAE) and how is it calculated?"
      ],
      "metadata": {
        "id": "cWHNSNKpz05C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Absolute Error (MAE) is a loss function in regression analysis used to measure the average absolute difference between the predicted values and the true values of the target variable. It provides a straightforward measure of the model's average prediction error.\n",
        "* Its advantages are: It is Robust to outliers. Also the error has same unit as dependent variable.\n",
        "* Disadvantage: Convergence usually takes time and its optimization is complex.\n",
        "\n",
        "Mathematically, the MAE can be represented as:\n",
        "\n",
        "MAE = SAE / n\n",
        "\n",
        "where SAE is the sum of absolute errors and n is the number of data points."
      ],
      "metadata": {
        "id": "mRCvpKvt14Hx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 25. What is log loss (cross-entropy loss) and how is it calculated?"
      ],
      "metadata": {
        "id": "P6GTKNQJz2js"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Log loss, also known as cross-entropy loss or logarithmic loss, is a loss function used in classification tasks, especially in binary classification or multi-class classification with probabilistic models.\n",
        "\n",
        "It measures the discrepancy between predicted class probabilities and the true class labels.\n",
        "\n",
        "Mathematically, the log loss (cross-entropy loss) can be represented as:\n",
        "\n",
        "Log Loss = (-1/n) * ∑[y * log(p) + (1 - y) * log(1 - p)]\n",
        "\n",
        "where y is the true class label (0 or 1), p is the predicted probability of the true class, and the summation is performed over all data points."
      ],
      "metadata": {
        "id": "WuQnP26C2zDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 26. How do you choose the appropriate loss function for a given problem?"
      ],
      "metadata": {
        "id": "tZ7PfoRSz4JW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Depending upon the type of problem statement and model, a suitable loss function needs to be selected from the set of available. Different parameters like type of machine learning algorithm, degrees of the percentage of outliers in the provided dataset, ease of calculating derivatives etc. play their role in choosing loss function.\n",
        "\n",
        "* Regression Loss Functions\n",
        "  1. Mean Squared Error Loss\n",
        "  2. Mean Squared Logarithmic Error Loss\n",
        "  3. Mean Absolute Error Loss\n",
        "* Binary Classification Loss Functions\n",
        "  1. Binary Cross-Entropy\n",
        "  2. Hinge Loss\n",
        "  3. Squared Hinge Loss\n",
        "* Multi-Class Classification Loss Functions\n",
        "  1. Multi-Class Cross-Entropy Loss\n",
        "  2. Sparse Multiclass Cross-Entropy Loss\n",
        "  3. Kullback Leibler Divergence Loss\n"
      ],
      "metadata": {
        "id": "86GFJ5nF2-RB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 27. Explain the concept of regularization in the context of loss functions."
      ],
      "metadata": {
        "id": "X4-r3hzhz6Cz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Regularization is a technique used to prevent the model from overfitting by adding some extra information into it.\n",
        "* It is commonly used in machine learning and statistical modelling to prevent overfitting and improve the generalization ability of the model.\n",
        "* The general form of regularized loss function is = Loss + Regularization Term.\n"
      ],
      "metadata": {
        "id": "vN_3FlEw0CXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 28. What is Huber loss and how does it handle outliers?"
      ],
      "metadata": {
        "id": "j1AZpJR5z9UV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Huber loss is a loss function that is commonly used in regression problems to balance the effects of outliers and inliers in the data.\n",
        "\n",
        "Unlike the mean squared error (MSE) loss, which treats all errors equally, the Huber loss gives less weight to large errors, making it more robust to outliers.\n",
        "\n",
        "The Huber loss function is defined as follows:\n",
        "\n",
        "Huber Loss = { 0.5 * (y - ŷ)^2 if |y - ŷ| ≤ δ\n",
        "{ δ * |y - ŷ| - 0.5 * δ^2 if |y - ŷ| > δ\n",
        "\n",
        "where y is the true value, ŷ is the predicted value, and δ is a parameter that determines the threshold for the transition between the quadratic and linear regions of the loss function."
      ],
      "metadata": {
        "id": "Ibed_wjY4JjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 29. What is quantile loss and when is it used?"
      ],
      "metadata": {
        "id": "NzIyl01Oz_GV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantile loss, also known as pinball loss, is a loss function used in quantile regression to measure the deviation between predicted quantiles and the true quantiles of a target variable.\n",
        "\n",
        "It is particularly useful when the goal is to estimate conditional quantiles of the response variable rather than the conditional mean.\n",
        "\n",
        "The quantile loss is defined as follows:\n",
        "\n",
        "Quantile Loss = ∑[ρ(y - ŷ)],\n",
        "\n",
        "where ρ is a function that determines the shape of the loss function, y is the true value, and ŷ is the predicted value."
      ],
      "metadata": {
        "id": "HoTriR2D4wzP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 30. What is the difference between squared loss and absolute loss?\n"
      ],
      "metadata": {
        "id": "nm8E_mjpYT62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Key difference between Squared loss and absolute loss is:\n",
        "1. Squared Loss is not Robust to outliers whereas Absolute Loss is Robust to outliers.\n",
        "2. Squared loss value has the unit which is squared to that of the dependent variable whereas the Absolute loss value has the same unit as compared to that of dependent variable values.\n",
        "3. Squared Loss function is differentiable, we can get local and global minima using squared loss function but there is convergence in absolute loss function.\n",
        "4. In absolute loss function, optimization is complex."
      ],
      "metadata": {
        "id": "VZN20zP9YT4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer (GD):"
      ],
      "metadata": {
        "id": "AW1zgkVKYT1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 31. What is an optimizer and what is its purpose in machine learning?"
      ],
      "metadata": {
        "id": "s1-JREUlYTxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizer refers to an algorithm or method used to adjust the parameters of a model to minimize the loss function and improve the model's performance.\n",
        "\n",
        "The optimizer plays a crucial role in the training process by iteratively updating the model's parameters based on the gradients of the loss function.\n",
        "\n",
        "The purpose of an optimizer in machine learning is to find the optimal set of parameter values that minimize the discrepancy between the predicted values and the true values of the target variable. It aims to improve the model's ability to generalize and make accurate predictions on unseen data."
      ],
      "metadata": {
        "id": "K1e1ejEp6HZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 32. What is Gradient Descent (GD) and how does it work?"
      ],
      "metadata": {
        "id": "IaGqzg2T6Qdv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent (GD) is an optimization algorithm used to iteratively update the parameters of a model in order to minimize a given loss function. It is widely used in machine learning and deep learning for parameter estimation and model training.\n"
      ],
      "metadata": {
        "id": "h8eDDhqS6TKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 33. What are the different variations of Gradient Descent?"
      ],
      "metadata": {
        "id": "5cRQN4Km6THn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 34. What is the learning rate in GD and how do you choose an appropriate value?"
      ],
      "metadata": {
        "id": "VaTKGDwr6TCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 35. How does GD handle local optima in optimization problems?"
      ],
      "metadata": {
        "id": "iObLwJ7E6S_o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 36. What is Stochastic Gradient Descent (SGD) and how does it differ from GD?"
      ],
      "metadata": {
        "id": "UQvpMp8g6S8h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 37. Explain the concept of batch size in GD and its impact on training."
      ],
      "metadata": {
        "id": "eS-f-LRj6wQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 38. What is the role of momentum in optimization algorithms?"
      ],
      "metadata": {
        "id": "NisD9liq6S54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 39. What is the difference between batch GD, mini-batch GD, and SGD?"
      ],
      "metadata": {
        "id": "Xj6X1fr76S27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 40. How does the learning rate affect the convergence of GD?"
      ],
      "metadata": {
        "id": "ezejQbNQ6Sz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ".\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I5uSBtc8YTtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regularization:"
      ],
      "metadata": {
        "id": "ay0CkkRQ65kv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "41. What is regularization and why is it used in machine learning?\n",
        "42. What is the difference between L1 and L2 regularization?\n",
        "43. Explain the concept of ridge regression and its role in regularization.\n",
        "44. What is the elastic net regularization and how does it combine L1 and L2 penalties?\n",
        "45. How does regularization help prevent overfitting in machine learning models?\n",
        "46. What is early stopping and how does it relate to regularization?\n",
        "47. Explain the concept of dropout regularization in neural networks.\n",
        "48. How do you choose the regularization parameter in a model?\n",
        "49. What\n",
        "\n",
        " is the difference between feature selection and regularization?\n",
        "50. What is the trade-off between bias and variance in regularized models?\n"
      ],
      "metadata": {
        "id": "1tDlREAx6-mV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM:\n",
        "\n",
        "51. What is Support Vector Machines (SVM) and how does it work?\n",
        "52. How does the kernel trick work in SVM?\n",
        "53. What are support vectors in SVM and why are they important?\n",
        "54. Explain the concept of the margin in SVM and its impact on model performance.\n",
        "55. How do you handle unbalanced datasets in SVM?\n",
        "56. What is the difference between linear SVM and non-linear SVM?\n",
        "57. What is the role of C-parameter in SVM and how does it affect the decision boundary?\n",
        "58. Explain the concept of slack variables in SVM.\n",
        "59. What is the difference between hard margin and soft margin in SVM?\n",
        "60. How do you interpret the coefficients in an SVM model?\n"
      ],
      "metadata": {
        "id": "6W2loIKe68z9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Trees:\n",
        "\n",
        "61. What is a decision tree and how does it work?\n",
        "62. How do you make splits in a decision tree?\n",
        "63. What are impurity measures (e.g., Gini index, entropy) and how are they used in decision trees?\n",
        "64. Explain the concept of information gain in decision trees.\n",
        "65. How do you handle missing values in decision trees?\n",
        "66. What is pruning in decision trees and why is it important?\n",
        "67. What is the difference between a classification tree and a regression tree?\n",
        "68. How do you interpret the decision boundaries in a decision tree?\n",
        "69. What is the role of feature importance in decision trees?\n",
        "70. What are ensemble techniques and how are they related to decision trees?\n"
      ],
      "metadata": {
        "id": "VtgKY6P57Ab8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble Techniques:\n",
        "\n",
        "71. What are ensemble techniques in machine learning?\n",
        "72. What is bagging and how is it used in ensemble learning?\n",
        "73. Explain the concept of bootstrapping in bagging.\n",
        "74. What is boosting and how does it work?\n",
        "75. What is the difference between AdaBoost and Gradient Boosting?\n",
        "76. What is the purpose of random forests in ensemble learning?\n",
        "77. How do random forests handle feature importance?\n",
        "78. What is stacking in ensemble learning and how does it work?\n",
        "79. What are the advantages and disadvantages of ensemble techniques?\n",
        "80. How do you choose the optimal number of models in an ensemble?\n",
        "\n"
      ],
      "metadata": {
        "id": "BYnXM6dV7AY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aerhD7ob7AV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JEd3SvkA7ASV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4uyk_DYV7AN5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IJX-N8qJ69N2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}